Metadata-Version: 2.4
Name: bee2bee
Version: 3.3.0
Summary: Decentralized P2P network for AI model hosting and inference
Author-email: ConnectIT Team <loaiabdalslam@gmail.com>
License: ConnectIT Custom License
        
        Copyright (c) 2024 ConnectIT Project
        
        Permission is hereby granted, free of charge, to any person obtaining a copy
        of this software and associated documentation files (the "Software"), to use,
        copy, modify, merge, publish, and distribute the Software for NON-COMMERCIAL
        purposes only, subject to the following conditions:
        
        NON-COMMERCIAL USE ONLY:
        This license permits use of the Software for personal, educational, research,
        and other non-commercial purposes. Any use that generates revenue, profit, or
        is part of a commercial enterprise is strictly prohibited under this license.
        
        COMMERCIAL USE:
        For any commercial use, including but not limited to:
        - Integration into commercial products or services
        - Use in revenue-generating applications
        - Distribution as part of commercial software
        - Use by commercial entities for business purposes
        
        You must obtain explicit written permission from the copyright holder.
        For commercial licensing inquiries, please contact: loaiabdalslam@gmail.com
        
        CONDITIONS:
        1. The above copyright notice and this permission notice shall be included in
           all copies or substantial portions of the Software.
        
        2. Any modifications or derivative works must also be distributed under this
           same license.
        
        3. You may not remove or alter any copyright notices or license terms.
        
        DISCLAIMER:
        THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
        IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
        FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
        AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
        LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
        OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
        SOFTWARE.
        
        For questions about this license or to request commercial usage rights,
        contact: loaiabdalslam@gmail.com
Keywords: p2p,ai,machine-learning,distributed,inference,transformers
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: Topic :: System :: Distributed Computing
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: click>=8.0
Requires-Dist: typer>=0.12
Requires-Dist: rich>=13.7
Requires-Dist: websockets>=12.0
Requires-Dist: psutil>=5.9
Requires-Dist: numpy>=1.24
Requires-Dist: fastapi>=0.104.0
Requires-Dist: uvicorn[standard]>=0.24.0
Requires-Dist: pydantic>=2.0.0
Provides-Extra: hf
Requires-Dist: transformers>=4.40; extra == "hf"
Requires-Dist: datasets>=2.17; extra == "hf"
Provides-Extra: onnx
Requires-Dist: onnx>=1.14; extra == "onnx"
Requires-Dist: onnxruntime>=1.17; extra == "onnx"
Provides-Extra: torch
Requires-Dist: torch>=2.1; (platform_system != "Windows" or platform_machine != "ARM64") and extra == "torch"
Provides-Extra: dht
Requires-Dist: kademlia>=2.2.2; extra == "dht"
Provides-Extra: nat
Requires-Dist: miniupnpc>=2.2.5; extra == "nat"
Requires-Dist: aiortc>=1.9.0; extra == "nat"
Provides-Extra: test
Requires-Dist: pytest; extra == "test"
Requires-Dist: httpx; extra == "test"
Provides-Extra: all
Requires-Dist: transformers>=4.40; extra == "all"
Requires-Dist: datasets>=2.17; extra == "all"
Requires-Dist: onnx>=1.14; extra == "all"
Requires-Dist: onnxruntime>=1.17; extra == "all"
Requires-Dist: torch>=2.1; (platform_system != "Windows" or platform_machine != "ARM64") and extra == "all"
Requires-Dist: kademlia>=2.2.2; extra == "all"
Requires-Dist: miniupnpc>=2.2.5; extra == "all"
Requires-Dist: aiortc>=1.9.0; extra == "all"
Dynamic: license-file

Bee2Bee
=======

<div align="center">
  <a href="https://www.producthunt.com/products/connect-it?embed=true&utm_source=badge-featured&utm_medium=badge&utm_source=badge-bee2bee" target="_blank"><img src="https://api.producthunt.com/widgets/embed-image/v1/featured.svg?post_id=1048013&theme=dark&t=1765265705335" alt="Bee2Bee - BEE2BEE&#0058;&#0032;Return&#0032;to&#0032;Decentralized&#0032;AI | Product Hunt" style="width: 250px; height: 54px;" width="250" height="54" /></a>
</div>

# Bee2Bee: Decentralized AI Network

**Bee2Bee** is a peer-to-peer network that allows you to easily deploy, route, and access AI models across any infrastructure (Local, Cloud, Colab) without complex networking configuration.

---

## üèó System Architecture

The ecosystem consists of four main components:

1.  **Main Point (Tracker/API)**: The central supervisor that tracks active peers and exposes the HTTP API.
2.  **Worker Nodes (Providers)**: Machines that run `deploy-hf` to host AI models and serve requests.
3.  **Desktop App (Frontend)**: An Electron+React UI for managing the network and chatting with models.
4.  **Bee2Bee Cloud (Colab)**: A Google Colab notebook acting as a Cloud Node using Hybrid Tunneling.

---

## üöÄ Quick Start Guide

### 1. Main End Point (The Supervisor)

This runs the core API server. Every network needs at least one Main Point.

**Run Locally:**
```bash
# Starts the API on Port 4002 and P2P Server on Port 4003
python -m bee2bee api
```
*Output:*
-   **API**: `http://127.0.0.1:4002` (Docs: `/docs`)
-   **P2P**: `ws://127.0.0.1:4003`

---

### 2. Desktop App (The Dashboard)

A modern UI to visualize the network and chat with models.

**Prerequisites:** Node.js 20+

**Run Locally:**
```bash
cd desktop-app
npm install      # First time only
npm run dev
```
*Usage:*
- Open the App.
- It connects to `http://localhost:4002` by default.
- Go to "Chat" to talk to available providers.

---

### 3. Worker Node (The AI Provider)

Run this on any machine (or the same machine) to share an AI model.

**Step A: Configure** (Tell the node where the Main Point is)
```bash
# If running on the SAME machine as Main Point:
python -m bee2bee config bootstrap_url ws://127.0.0.1:4003

# If running on a DIFFERENT machine (LAN/WAN):
python -m bee2bee config bootstrap_url ws://<MAIN_POINT_IP>:4003
```

**Step B: Deploy Model**

**Option 1: Hugging Face (Default)**
Uses `transformers` to run models like GPT-2, Llama, etc. on CPU/GPU.
```bash
# Deploys distilgpt2 (CPU friendly)
python -m bee2bee deploy-hf --model distilgpt2
```

**Option 2: Ollama (Universal)**
Uses your local Ollama instance to serve models like Llama3, Mistral, Gemma, etc.
*Prerequisite: Install and run [Ollama](https://ollama.com)*
```bash
# Serve a model (e.g., llama3)
python -m bee2bee serve-ollama --model llama3
```
*Note: This creates a separate peer node on your machine.*

---

### 4. Bee2Bee Cloud (Google Colab)

Run a powerful node on Google's free GPU infrastructure using our **Hybrid Tunneling** setup.

**Notebook Location**: `notebook/ConnectIT_Cloud_Node.ipynb`

**How it Works (Hybrid Tunneling):**
To bypass Colab's network restrictions, we use two tunnels:
1.  **API Tunnel (Cloudflare)**: Provides a stable HTTPS URL (`trycloudflare.com`) for the Desktop App to connect to.
2.  **P2P Tunnel (Bore)**: Provides a raw WebSocket URL (`bore.pub`) for other Worker Nodes to connect to.

**Instructions:**
1.  Open the Notebook in Google Colab.
2.  Run **"Install Dependencies"**.
3.  Run **"Configure Hybrid Tunnels"** (Installs `cloudflared` & `bore`).
    - *Wait for it to output the URLs.*
4.  Run **"Run Bee2Bee Node"**.
    - *It automatically configures itself to announce the Bore address.*

**Connecting your Desktop App to Colab:**
1.  Copy the **Cloudflare URL** (e.g., `https://funny-remote-check.trycloudflare.com`).
2.  Open Desktop App -> Settings.
3.  Paste into "Main Point URL".

---

## üõ† Advanced Configuration

### Environment Variables
You can override settings using ENV vars:

| Variable | Description | Default |
| :--- | :--- | :--- |
| `BEE2BEE_PORT` | Port for P2P Server | `4003` (Worker) / `4003` (API) |
| `BEE2BEE_HOST` | Bind Interface | `0.0.0.0` |
| `BEE2BEE_ANNOUNCE_HOST` | Public Hostname (for NAT/Tunnel) | Auto-detected |
| `BEE2BEE_ANNOUNCE_PORT` | Public Port (for NAT/Tunnel) | Auto-detected |
| `BEE2BEE_BOOTSTRAP` | URL of Main Point | `None` |

### Troubleshooting
-   **"Connection Refused"**: Ensure the `bootstrap_url` is correct and reachable (try `ping`).
-   **"0 Nodes Connected"**: Check if the Worker Node can reach the Main Point's P2P address (WSS).
-   **Colab Disconnects**: Ensure the Colab tab stays open. Tunnels change if you restart the notebook.

---

## ü§ù Contributing
Contributions are welcome! Please open an issue or PR on [GitHub](https://github.com/Chatit-cloud/BEE2BEE).
